\documentclass[a4paper, 10pt]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsfonts,amssymb,amsmath,amscd,amsthm,latexsym}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\newcommand{\Esp}{\mathbb{E}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Jcal}{\mathcal{J}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Pcal}{\mathcal{P}}
\renewcommand{\Pr}{\mathbb{P}}
\newcommand{\Tcal}{\mathcal{T}}

\title{Divergence between distributions over spanning trees}
\author{SR}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Consider two distributions $F$ and $G$ over the set of spanning $\Tcal$ of a complete graph with $p$ nodes. Both $F$ and $G$ are supposed to be factorizable, that is:
$$
\forall T \in \Tcal, \qquad
f(T) = \prod_{j, k \in T} a_{jk} / A, \qquad
g(T) = \prod_{j, k \in T} b_{jk} / B.
$$

\paragraph{Some facts.}
\begin{enumerate}
 \item The number of spanning trees (i.e. the cardinal of $\Tcal$) is $p^{p-2}$.
 \item The number of spanning trees containing a given edge is $2p^{p-3}$.
 \item The normalizing constants $A$ and $B$ can be computed using the Matrix-Tree theorem \cite{Cha82}, which enables to compute efficiently any quantity of the form
 \begin{equation} \label{eq:MTT}
 \sum_{T \in \Tcal} \prod_{jk \in T} x_{jk}.
 \end{equation}
 \item We denote by $F_{jk}$ (resp. $G_{jk}$) the probability for edge $(j, k)$ to be part of $T$ under $F$ (resp. $G$), that is
 $$
 F_{jk} = \sum_{T \ni jk} f(T).
 $$
 All $F_{jk}$ and $G_{jk}$ can be computed using an avatar of the Matrix-Tree theorem \cite{Kir07}.
\end{enumerate}

\paragraph{Problem:} 
Compute some distance or divergence between $F$ and $G$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Some computable divergences} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{$\alpha$-divergences} 

\paragraph{Definition.} \cite{Min05}
$$
D_\alpha(F || G) = \frac1{\alpha (1-\alpha)} \left(1 - \sum_{T \in \Tcal} f(T)^\alpha g(T)^{1 - \alpha} \right)
$$

\paragraph{Examples.} The Hellinger ($\alpha = 1/2$), Chi-square ($\alpha = 2$) and the Küllback-Leibler ($\alpha \rightarrow 0$ or $1$) divergences are $\alpha$-divergences.

\paragraph{Property.}  All $\alpha$-divergences are comptable via the Matrix-Tree theorem. Indeed
$$
\sum_{T \in \Tcal} f(T)^\alpha g(T)^{1 - \alpha} 
 = \frac{B}{A} \sum_{T \in \Tcal} \prod_{jk \in T} (a_{jk})^{\alpha} (b_{jk})^{1 - \alpha},
$$
which has the form \eqref{eq:MTT}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bregman divergences} 

\paragraph{Definition.} For any convex function $\phi$, a Bregman divergence\footnote{\url{https://en.wikipedia.org/wiki/Bregman_divergence}} can be defined as 
$$
D_\phi(F \| G) = \phi(F) - \phi(G) - <\nabla \phi(F), F - G>.
$$

\paragraph{Examples.} The Küllback-Leibler and the Itakura-Saito divergences are Bregman divergences.

\paragraph{Property.}  The Küllback-Leibler divergence is comptable via the Matrix-Tree theorem. Indeed
\begin{align*}
 KL(F || G) 
 & = \sum_{T \in \Tcal} f(T) \log \frac{f(T)}{g(T)} 
 \qquad = \sum_{T \in \Tcal}  f(T) \sum_{jk \in T} \log \frac{a_{jk}}{b_{jk}} + \log \frac{B}{A} \\
 & = \sum_{jk} \log \frac{a_{jk}}{b_{jk}} \left(\sum_{t \ni jk} f(T) \right) 
 + \log \frac{B}{A} 
 \qquad = \sum_{jk} F_{jk} \log \frac{a_{jk}}{b_{jk}} + \log \frac{B}{A}.
\end{align*}


\paragraph{Property.}  The Itakura-Saito divergence is comptable via the Matrix-Tree theorem. Indeed
$$
IS(F || G) 
= \sum_{T \in \Tcal} \left( \frac{f(T)}{g(T)} - \log \frac{f(T)}{g(T)} - 1 \right)
$$
where
$$
\sum_{T \in \Tcal} \frac{f(T)}{g(T)}
= \frac{B}{A} \sum_{T \in \Tcal}  \prod_{jk \in T} \frac{a_{jk}}{b_{jk}}
$$
which has the form \eqref{eq:MTT}, and
\begin{align*}
 \sum_{T \in \Tcal} \log \frac{f(T)}{g(T)} 
 & = \sum_{T \in \Tcal} \log \frac{B}{A} + \sum_{T \in \Tcal} \sum_{jk \in T} \log \frac{a_{jk}}{b_{jk}} 
 \qquad = p^{p-2} \log \frac{B}{A} + \sum_{jk} \#\{T \in T: jk \in T\} \log \frac{a_{jk}}{b_{jk}}  \\
 & = p^{p-2} \log \frac{B}{A} + 2p^{p-3}\sum_{jk} \log \frac{a_{jk}}{b_{jk}} 
\end{align*}
so
$$
IS(F || G) 
= \frac{B}{A} \sum_{T \in \Tcal} \prod_{jk \in T} \frac{a_{jk}}{b_{jk}} 
- p^{p-2} \log \frac{B}{A} - 2p^{p-3}\sum_{jk} \log \frac{a_{jk}}{b_{jk}}
- p^{p-2}.
$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \section{Testing hypotheses in the PLNtree model} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{PLNtree model.}
\begin{itemize}
 \item $T \sim f(\cdot; \beta)$;
 \item $\{Z_i\}_{1 \leq i \leq n}$ iid $\mid T$: $Z_i \mid T \sim \Ncal(0, \Omega_T)$, each $\Omega_T$ being extracted from a unique matrix $\Omega$ according to $T$;
 \item $\{Y_{ij}\}_{1 \leq i \leq n, 1 \leq j \leq p}$ indep. $\mid \{Z_i\}$: $Y_{ij} \mid Z_{ij} \sim \Pcal(e^{x_i^\intercal \theta_j + Z_{ij}})$.
\end{itemize}

\paragraph{Problem.} Consider data arising from two sites (1 and 2): Test
$$
H_0^\beta = \{\beta^1 = \beta^2\}
$$
or
$$
H_0^{\beta \Omega} = \{(\beta^1, \Omega^1) = (\beta^2, \Omega^2)\}
$$
using a likelihood ratio test (LRT).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inference of the PLNtree} 

Following \cite{MRA19}, we aim at minimizing the lower bound 
\begin{align*}
 \Jcal(\beta, \Omega, \theta; h, g) 
 & = \log p_{\beta, \Omega, \theta}(Y) - KL(h(Z) \otimes g(T) || p(Z, T \mid Y)) \\
 & = \Esp_{g, h} \log p_{\beta, \Omega, \theta}(Y, Z, T) + \Hcal(h) + \Hcal(g) \\
 & = \Esp_{g} \log p_{\beta}(T) + \Esp_{g, h} \log p_{\Omega_T}(Z) 
 + \Esp_{h} \log p_{\beta}(Y \mid Z) + \Hcal(h) + \Hcal(g) 
\end{align*}
where $h(T)$ is a tree distribution parametrized with $(\widetilde{\beta}_{kl})$ and $g$ is a product of multivariate diagonal Gaussian distributions: $h(Z) = \prod_{i=1}^n \Ncal(Z_i; \widetilde{m}_i, \widetilde{S}_i)$.

\paragraph{2-step procedure.} 
Because
\begin{align*}
 \Jcal(\beta, \Omega, \theta; g, h) 
 = & \; \Esp_{h} \log p_{\Omega}(Z) + \Esp_{h} \log p_{\beta}(Y \mid Z) + \Hcal(h) & & (a)\\
 & + \Esp_{g, h} \log p_{\Omega_T}(Z) - \Esp_{h} \log p_{\Omega}(Z) & & (b)\\
%  \Jcal_3(\beta, \Omega; g, h)
 & + \Esp_{g} \log p_{\beta}(T) + \Hcal(g), & & (c)
\end{align*}
we first use a VEM algorithm to fit (using \url{PLNmodels})
$$
(\widehat{\Omega}, \widehat{\theta}, \widetilde{h}) = \arg\max_{\Omega, \theta, h} \; \Esp_{h} \log p_{\Omega}(Z) + \Esp_{h} \log p_{\theta}(Y \mid Z) + \Hcal(h),
$$
and then use an EM algorithm to fit (using \url{EMtree})
$$
(\widehat{\beta}, \widetilde{g}) = \arg\max_{\beta, g} \; \Esp_{g, \widetilde{h}} \log p_{\widehat{\Omega}_T}(Z) + \Esp_{g} \log p_{\beta}(T) + \Hcal(g).
$$

\paragraph{Evaluation of the resulting lower bound.} After optimization we have that
\begin{align*}
 \Esp_{\widetilde{h}} \log p_{\widehat{\Omega}}(Z)
 & = \frac{n}2 \log |\widehat{\Omega}| - \frac{np}2, \\
 \Esp_{\widetilde{h}} \log p_{\widehat{\theta}}(Y \mid Z)
 & = \sum_{i, j} - e^{x_i^\intercal \widehat{\theta}_j + \widetilde{m}_{ij} + \widetilde{s}_{ijj}^2/2} + Y_{ij} (x_i^\intercal \widehat{\theta}_j + \widetilde{m}_{ij}) - \log(Y_{ij} !), \\
 \Hcal(\widetilde{h})
 & = - \frac12 \sum_i \log|\widetilde{S}_i|
 = - \frac12 \sum_{i, j} \log|\widetilde{s}_{ij}^2|, \\
 \Esp_{\widetilde{g}, \widetilde{h}} \log p_{\widehat{\Omega}_T}(Z)
 & = 
 \frac{n}2 \sum_j \log \widehat{\omega}_{jj} 
 + \frac12 \sum_{i, j} \widehat{\omega}_{jj} (\widetilde{m}_{ij}^2 + \widetilde{s}_{ij}^2) 
 + \frac{n}2 \sum_{j < k} \widetilde{P}_{jk} \log(1 - \widehat{\rho}_{kl}^2)
 + \sum_{i, j < k} \widetilde{P}_{jk} \widehat{\omega}_{jk} \widetilde{m}_{ij} \widetilde{m}_{ik}, \\
 \Esp_{\widetilde{g}} \log p_{\widehat{\beta}}(T) 
 & = \sum_{j < k} \widetilde{P}_{jk} \log \widehat{\beta}_{jk} - \log \widehat{B}, 
\\
 \Hcal(\widetilde{g})
 & = - \sum_{j < k} \widetilde{P}_{jk} \log \widetilde{\beta}_{jk} + \log \widetilde{B}
\end{align*}
 where $\widetilde{P}_{jk} = \Pr_{\widetilde{g}}\{jk \in T\}$. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage 
\bibliography{/home/robin/Biblio/BibGene}
\bibliographystyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

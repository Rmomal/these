\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, mathtools}
\usepackage{amsfonts, dsfont}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{empheq}
\usepackage[round, sort]{natbib}

\newcommand*\widefbox[1]{\fbox{\hspace{3em}#1\hspace{3em}}}

\newcommand*\lesswidefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}

\providecommand\given{} % is redefined in \Set
\newcommand\SetSymbol[1][]{\nonscript\:#1\vert\nonscript\:}
%\usepackage[mathcal]{eucal}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\setlength\parindent{0pt}
\author{Raphaelle Momal}
\title{PLN with missing actor}


\newcommand{\Esp}{\mathds{E}}
\newcommand{\entr}{\mathcal{H}}
\begin{document}
\maketitle


We had: 
$$ p(Y,Z,T) = p(T)p(Z|T)p(Y|Z)$$
$$ \Esp(\log p(Y,Z,T)|Y) \approx \sum_{1 \leq j < k \leq p} P_{jk} \log\left(\beta_{jk} \hat{\psi}_{jk}\right) - \log B + cst$$

We want to add a hidden layer of unobserved data, indexed by H.

$$ p(Y,Z_O,Z_H,T)$$
\section{PLNmissing peculiarities: Model and distributions}



$$\left\{\begin{array}{rl}
T & \sim\prod_{jk \in T} \beta_{jk}/B \\\\

Z|T& \sim\mathcal{N}(0,\Sigma_T)\\\\

Y|Z&\sim\mathcal{P}( \exp( Z+...) )
\end{array} \right.$$


\paragraph{Dimensions:}
The model is build on matrices $Y$ and $Z$ with the following dimensions:\\
$Y$: $n\times p$\\
$Z_O$: $n\times p$\\
$Z_H$: $n\times r$

\paragraph{Marginals}
\begin{align*}
(Z_O,Z_H) &\sim \sum_{T \in \mathcal{T}} p(T) \mathcal{N}(0,\Sigma_T) \\
\end{align*}

\paragraph{Conditional on T:}
\begin{align*}
(Z_O,Z_H)|T & \sim\mathcal{N}(0,\Sigma_T)\\
Z_O|T & \sim\mathcal{N}(0,\Omega_{Tm}^{-1})\\
Z_H|T & \sim\mathcal{N}(0,\Omega_{TH}^{-1})
\end{align*}
With $ \Omega_{Tm} =\Sigma_{TO}^{-1} =  \Omega_{TO} - \Omega_{TOH}\Omega_{TH}^{-1}\Omega_{THO}$


\paragraph{Conditional on observed data:\\}


$Z_O$ decouples $Z_H$ and $Y$, we will never need $Z_H|Y$.
$$ p(Z|Y) = p(Z_O,Z_H | Y) = p(Z_H|Z_O) \: p(Z_O|Y) $$


VEM on observed data: $$Z_O|Y \approx \widetilde{Z}_O \sim \mathcal{N}(m,S)$$

 
Model for the hidden part: $$Z_H|Z_O,T \sim \mathcal{N}(\mu_{H|O,T}, \Omega_{H}^{-1})$$ 

\begin{itemize}
\item $\Omega_{TH|O}^{-1} = \Sigma_{TH} -\Sigma_{THO}\Sigma_{TO}^{-1}\Sigma_{TOH} = \Omega_{TH}^{-1}$, moreover the H block of $\Omega_T$ is diagonal as imposed by identifiability conditions, and diagonal terms do not depend on tree $T$  by construction/hypothesis. Hence $\Omega_{TH|O}^{-1}=\Omega_{H}^{-1}$.

\item$ \displaystyle\begin{aligned}[t]
\mu_{H|O,T} &= \Sigma_{THO}\Sigma_{TO}^{-1}(Z_O-\underbrace{\mu_{Z_O|T}}_{0}) \\
 &= -\Omega_{TH}^{-1}\Omega_{TOH} \: Z_O
\end{aligned}$\\
\end{itemize}


\paragraph{Joint:}
\begin{align*}
p(Y,Z,T)& = p(T) \: p(Z|T) \: p(Y|Z) \\
&= p(T)\: p(Z_O,Z_H|T) \: p(Y|Z_O,Z_H) \\
&= p(T) \: p(Z_O|T) \: p(Z_H | Z_O,T)  \: p(Y|Z_O)
\end{align*} 
\section{Variational EM inference}

This variational EM approximates the conditional distribution $p(T,Z | Y)$ by a product  between the  distributions of tree $T$ and latent variables $Z$.

$$p(T,Z | Y) \approx  g(T)h(Z)$$
\begin{itemize}
\item $ h(Z_i) =  \mathcal{N}(m_i,S_i)\text{, with marginals conveniently written as } h_O \text{ and } h_H $
\item $ h(Z) = \prod_i h(Z_i)$ ($\approx$ mean-field approximation ?)
\item $ g(T) = \left(\prod_{kl} \widetilde{\beta}_{kl} \right) / \widetilde{B}$
\end{itemize}


\subsection{Lower bound:}
Starting with the two hidden layers of our model, the lower bound writes:
\begin{align*}
\mathcal{J}(Y; g,h)&=\log p(Y) - KL\left[g(T) h(Z) \middle\vert\middle\vert\ p(T,Z | Y)\right]\\
&= \log p(Y) - \Esp_{gh}[\log( g(T) h(Z)) - \log p(Z,T\mid Y) ]\\
&= \log p(Y) - \Esp_{gh}[\log g(T) + \log h(Z) ] + \Esp_{gh}[\log p(Y,Z,T)] - \Esp_{gh}[\log p(Y)]\\
&= \Esp_{gh} [\log p(Y,Z,T)] + \entr[g(T)] + \entr[h(Z)]\\
&= \Esp_{gh} [\log p(T)p(Z\mid T)p(Y\mid Z)] + \entr[g(T)] + \entr[h(Z)]
\end{align*}

Adding modelization of unobserved covariates:
\begin{align*}
\mathcal{J}(Y; g,h)&= \Esp_{gh}[\log p(T)  p(Z_H| Z_O,T) p(Z_O|T)p(Y|Z_O)] + \entr[g(T)] +\entr[h(Z_H,Z_O)]
\end{align*}

 We develop the entropy of the complete $Z$ vector, to make the entropy of the fully observed part appear:
\begin{align*}
\entr[h(Z_H,Z_O)] &= -\Esp_h[\log h(Z_H,Z_O)]\\
&=-\Esp_h[\log h(Z_H\mid Z_O) h(Z_O)]\\
&=\entr[h(Z_O)] -\Esp_h[\log h(Z_H\mid Z_O)]
\end{align*}

Now using the hypothesis of independence of $g$ and $h$, we can obtain quantities with seperate dependencies:

\begin{align*}
\mathcal{J}(Y; g,h)&=   \Esp_{gh}[\log p(Z_H | Z_O,T)  p(Z_O | T)] +\Esp_g[\log p(T)] + \Esp_h[\log p(Y|Z_O)]-\Esp_h[\log h(Z_H\mid Z_O)]&\\
& \;\; + \entr[g(T)] +\entr[h(Z_O)] 
\end{align*}




%Property of Shannon entropy : $\entr(X,Y) = \entr(X) + \entr(Y|X)$

Finally we obtain:

\begin{align}
\mathcal{J}(Y; g,h)&=  \Esp_{gh}[\log p(Z_O | T)] +\Esp_h[\log p(Y|Z_O)]+\entr[h(Z_O)]& \text{: PLN like} \nonumber\\
& \;\; + \Esp_{gh}[\log p(Z_H | Z_O,T) ]+\Esp_g[\log p(T)] +\entr[g(T)]-\Esp_h[\log h(Z_H\mid Z_O)]&\text{: New}\label{lowerbound}
\end{align}\\

\subsection{Optimizing in $h(Z_O)$: PLNmodels}
\citet{CMR18} compute the lower bound of a VEM for the PLN, which we write $\mathcal{J}_{PLN}$. This lower bound appears in our computation as well. Let's first detail the following quantity:
\begin{align*}
\Esp_{gh}[\log p(Z_O|T)] &=  \Esp_{gh} \left[\frac{n}{2} \log |\Omega_{Tm}| - \frac{1}{2} \sum_i Z_{Oi}\Omega_{Tm} Z_{Oi}^T \right]\\
&= \frac{n}{2} \Esp_g [\log |\Omega_{Tm}|] - \frac{1}{2} \Esp_{gh}\left[Tr\left( Z_O^TZ_O \Omega_{Tm}\right)\right].
\end{align*}
The expectation in $gh$ is separable thanks to the independance hypothesis:
\begin{align*}
\Esp_{gh}[\log p(Z_O|T)] &=\frac{n}{2} \Esp_g [\log |\Omega_{Tm}|] - \frac{1}{2}  Tr\left(\Esp_h [Z_O^TZ_O ]\; \Esp_g[\Omega_{Tm}]\right)\\
&=\frac{n}{2} \Esp_g [\log |\Omega_{Tm}|] - \frac{1}{2}<\Esp_h [Z_OZ_O^T], \underbrace{\Esp_g [\Omega_{Tm}]}_{\overline{\Omega_{Tm}}}> .
\end{align*}
We note $\Esp_g [\Omega_{Tm}] = \overline{\Omega_{Tm}}$, which is a $p\times p$ matrix of expected covariance over the whole spanning-tree space. Introducing the quantity  $\log |\overline{\Omega_{Tm}}| $ in the PLN-like terms of Eq.~(\ref{lowerbound}), the lower bound of the VEM of PLN $\mathcal{J}_{PLN}$ appears:
\begin{align*}
&\Esp_{gh}[\log p(Z_O | T)] +\Esp_h[\log p(Y|Z_O)]+ \entr[h(Z_O)]\\
& =\underbrace{\frac{n}{2} \log |\overline{\Omega_{Tm}}| - \frac{1}{2}<\Esp_h [Z_OZ_O^T], \overline{\Omega_{Tm}}> + \Esp_{h}[\log p(Y|Z_O)] + \entr[h(Z_O)]}_{\mathcal{J}_{PLN}\text{ with } \widetilde{\Sigma} = \overline{\Omega_{Tm}}} + \underbrace{\frac{n}{2}\left( \Esp_g[\log|\Omega_{Tm}|] - \log|\overline{\Omega_{Tm}}|\right)}_{\leq 0}
\end{align*}


The second brace is a negative quantity, because the log determinent is a concave function. Jensen's inequality gives:
$$\log |\Esp_g[\Omega_{Tm}]| \geq \Esp_g [\log |\Omega_{Tm}|]$$
%$$ \Esp[Z_jZ_k] = -\partial_{\omega_{jk}}( \log |\Omega_{TO}| )$$
Therefore, $$\Esp_{gh}[\log p(Z_O | T)] +\Esp_h[\log p(Y|Z_O)]+ \entr[h(Z_O)] \leq \mathcal{J}_{PLN}$$\\


Remarks:
\begin{itemize}
\item Here it shows that assuming a tree structure for the latent layer of parameters $Z$ reveals an average precision matrix over all the precision matrices of possible trees. Recall that these matrices only differ in the position of their zero entries.
\item All terms depending on $h_O$ are taken care of in the PLN VEM. After optimizing in $h_O$, this density is constant and written $h_O^*$. The complete loss now still needs to be optimized in the ther parameters: $g$ and $h_H$.
\end{itemize}




\subsection{Optimizing in $g$ and $h_H$}
\begin{align*}
\mathcal{J}(Y; g,h)&= \Esp_{gh}[\log p(T) + \log p(Z|T) + \log p(Y|Z_O)] + \entr[g ] +\entr[h(Z_H,Z_O)]\\
&= \Esp_g[\log p(T)] + \Esp_{gh}[\log p(Z|T)] + \Esp_{h_O^*}[\log p(Y|Z_O)] + \entr[g ] +\entr[h(Z_H,Z_O)]
\end{align*}




\subsubsection{$ \entr[h(Z_H|Z_O)]$}

\begin{align*}
\entr[h(Z_H|Z_O)] &=   - \Esp_{Z_O}\left[\Esp_{Z_H|Z_O}[\log p(Z_H| Z_O)]\right]\\
&= \Esp_{Z_O}\left[\entr[Z_H|Z_O]\right]\\
&= 
\end{align*}

\bibliographystyle{apsrev} %tested plainnat
\bibliography{bibi}

\end{document}
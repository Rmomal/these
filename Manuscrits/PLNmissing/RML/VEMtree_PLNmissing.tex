\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, mathtools}
\usepackage{amsfonts, dsfont}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{empheq}

\newcommand*\widefbox[1]{\fbox{\hspace{3em}#1\hspace{3em}}}

\newcommand*\lesswidefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}

\providecommand\given{} % is redefined in \Set
\newcommand\SetSymbol[1][]{\nonscript\:#1\vert\nonscript\:}
%\usepackage[mathcal]{eucal}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\setlength\parindent{0pt}
\author{Raphaelle Momal}
\title{PLN with missing actor}


\newcommand{\Esp}{\mathds{E}}
\newcommand{\entr}{\mathcal{H}}
\begin{document}
\maketitle


We had: 
$$ p(Y,Z,T) = p(T)p(Z|T)p(Y|Z)$$
$$ \Esp(\log p(Y,Z,T)|Y) \approx \sum_{1 \leq j < k \leq p} P_{jk} \log\left(\beta_{jk} \hat{\psi}_{jk}\right) - \log B + cst$$

We want to add a hidden layer of unobserved data, indexed by H.

$$ p(Y,Z_O,Z_H,T)$$
\section{PLNmissing peculiarities: Model and distributions}
$$\left\{\begin{array}{rl}
T & \sim\prod_{jk \in T} \beta_{jk}/B \\\\

Z|T& \sim\mathcal{N}(0,\Sigma_T)\\\\

Y|Z&\sim\mathcal{P}( \exp( Z+...) )
\end{array} \right.$$

\paragraph{Marginals}
\begin{align*}
(Z_O,Z_H) &\sim \sum_{T \in \mathcal{T}} p(T) \mathcal{N}(0,\Sigma_T) \\
\end{align*}

\paragraph{Conditional on T:}
\begin{align*}
(Z_O,Z_H)|T & \sim\mathcal{N}(0,\Sigma_T)\\
Z_O|T & \sim\mathcal{N}(0,\Omega_{Tm}^{-1})\\
Z_H|T & \sim\mathcal{N}(0,\Omega_{TH}^{-1})
\end{align*}
With $ \Omega_{Tm} =\Sigma_{TO}^{-1} =  \Omega_{TO} - \Omega_{TOH}\Omega_{TH}^{-1}\Omega_{THO}$


\paragraph{Conditional on observed data:\\}


$Z_O$ decouples $Z_H$ and $Y_O$, we will never need $Z_H|Y_O$.
$$ p(Z|Y_O) = p(Z_O,Z_H | Y_O) = p(Z_H|Z_O) \: p(Z_O|Y_O) $$


VEM on observed data: $$Z_O|Y_O \approx \widetilde{Z}_O \sim \mathcal{N}(m,S)$$

\underline{ Hypothesis:}
$$ Z_O|Y,T \sim \mathcal{N}(m_T,S_T)$$

Model for the hidden part: $$Z_H|Z_O,T \sim \mathcal{N}(\mu_{H|O,T}, \Omega_{H}^{-1})$$ 

\begin{itemize}
\item $\Omega_{TH|O}^{-1} = \Sigma_{TH} -\Sigma_{THO}\Sigma_{TO}^{-1}\Sigma_{TOH} = \Omega_{TH}^{-1}$, moreover the H block of $\Omega_T$ is diagonal as imposed by identifiability conditions, and diagonal terms do not depend on tree $T$  by construction/hypothesis. Hence $\Omega_{TH|O}^{-1}=\Omega_{H}^{-1}$.

\item$ \displaystyle\begin{aligned}[t]
\mu_{H|O,T} &= \Sigma_{THO}\Sigma_{TO}^{-1}((Z_O)-\underbrace{\mu_{Z_O|T}}_{0}) \\
 &= -\Omega_{TH}^{-1}\Omega_{TOH} \: Z_O
\end{aligned}$\\
\end{itemize}


\paragraph{Joint:}
\begin{align*}
p(Y,Z,T)& = p(T) \: p(Z|T) \: p(Y|Z) \\
&= p(T)\: p(Z_O,Z_H|T) \: p(Y|Z_O,Z_H) \\
&= p(T) \: p(Z_O|T) \: p(Z_H | Z_O,T)  \: p(Y|Z_O)
\end{align*} 
\section{Variational EM inference}

This variational EM approximates the conditional distribution $p(T,Z | Y)$ by a product  between the  distributions of tree $T$ and latent variables $Z$.

$$p(T,Z | Y) \approx  g(T)h(Z)$$
\begin{itemize}
\item $ h(Z_i) =  \mathcal{N}(m_i,S_i)\text{, with marginals conveniently written as } h_O \text{ and } h_H $
\item $ h(Z) = \prod_i h(Z_i)$ ($\approx$ mean-field approximation ?)
\item $ g(T) = \left(\prod_{kl} \widetilde{\beta}_{kl} \right) / \widetilde{B}$
\end{itemize}


\subsection{Lower bound:}
Using the separability of $g$ and $h$:
\begin{align*}
\mathcal{J}(Y; g,h)&=\log p(Y) - KL\left[g(T) h(Z) \middle\vert\middle\vert\ p(T,Z | Y)\right]&\\
&= \log p(Y) - \Esp_{gh}[\log g(T) + \log h(Z) - \log p(Y,Z,T) + \log p(Y) ]&\\
&= - \Esp_{gh}[\log g(T) + \log h(Z) - \log p(Y,Z,T) ]&\\
&= \Esp_{gh} [\log p(Y,Z,T)] + \entr[g(T)] + \entr[h(Z)]& \\
&= \Esp_{gh}[\log p(T) + \log p(Z_H| Z_O,T)  + \log p(Z_O|T) + \log p(Y|Z_O)] + \entr[g(T)] +\entr[h(Z_H,Z_O)]&\\
&= \Esp_g[\log p(T)] + \Esp_{gh}[\log p(Z_H | Z_O,T) ] + \Esp_{gh}[\log p(Z_O | T)] + \Esp_h[\log p(Y|Z_O)]&\\
& \;\; + \entr[g(T)] +\entr[h(Z_O)]+ \entr[h(Z_H|Z_O)]
\end{align*}

%Property of Shannon entropy : $\entr(X,Y) = \entr(X) + \entr(Y|X)$

We obtain:
\begin{align*}
\mathcal{J}(Y; g,h)&= \Esp_h[\log p(Y|Z_O)]+ \Esp_{gh}[\log p(Z_O | T)] +\entr[h_O]& \} \text{PLN like}\\
& \;\; + \Esp_{gh}[\log p(Z_H | Z_O,T) ]+\Esp_g[\log p(T)] +\entr[g]+ \entr[h(Z_H|Z_O)] & \}\text{New terms}
\end{align*}\\

\subsection{Optimizing in $h_O$: PLNmodels}
We can make the very terms of PLN VEM appear.
\begin{align*}
\Esp_{gh}[\log p(Z_O|T)] &=  \Esp_{gh} \left[\frac{n}{2} \log |\Omega_{TO}| - \frac{1}{2} ||Z_O||_{\Omega_{TO}}^2 \right]\\
&=\frac{n}{2} \Esp_g [\log |\Omega_{TO}|] - \frac{1}{2}<\Esp_h [Z_OZ_O^T], \underbrace{\Esp_g [\Omega_{TO}]}_{\overline{\Omega_{TO}}}> 
\end{align*}
Then,
\begin{align*}
&\Esp_{gh}[\log p(Z_O | T)] +\Esp_h[\log p(Y|Z_O)]+ \entr[h_O]\\
& =\underbrace{\frac{n}{2} \log |\overline{\Omega_{TO}}| - \frac{1}{2}<\Esp_h [Z_OZ_O^T], \overline{\Omega_{TO}}> + \Esp_{h_O}[\log p(Y|Z_O)] + \entr[h_O]}_{\text{VEM of PLN with } \widetilde{\Sigma} = \overline{\Omega_{TO}}} + \frac{n}{2} \Esp_g[\log|\Omega_{TO}|] - \frac{n}{2} \log|\overline{\Omega_{TO}}|
\end{align*}

Remark: the log of the determinent is a concave function:
$$\log |\Esp_g[\Omega_{TO}]| \geq \Esp_g [\log |\Omega_{TO}|]$$
%$$ \Esp[Z_jZ_k] = -\partial_{\omega_{jk}}( \log |\Omega_{TO}| )$$
So this is an approximation, not a lower bound.\\

All terms depending on $h_O$ are taken care of in the PLN VEM. After optimizing in $h_O$, this density is constant and we write $h_O^*$. Back to the complete loss, we still need to optimize in other parameters: $g$ and $h_H$.

\subsection{Optimizing in $g$ and $h_H$}
\begin{align*}
\mathcal{J}(Y; g,h)&= \Esp_{gh}[\log p(T) + \log p(Z|T) + \log p(Y|Z_O)] + \entr[g ] +\entr[h(Z_H,Z_O)]\\
&= \Esp_g[\log p(T)] + \Esp_{gh}[\log p(Z|T)] + \Esp_{h_O^*}[\log p(Y|Z_O)] + \entr[g ] +\entr[h(Z_H,Z_O)]
\end{align*}




\subsubsection{$ \entr[h(Z_H|Z_O)]$}

\begin{align*}
\entr[h(Z_H|Z_O)] &=   - \Esp_{Z_O}\left[\Esp_{Z_H|Z_O}[\log p(Z_H| Z_O)]\right]\\
&= \Esp_{Z_O}\left[\entr[Z_H|Z_O]\right]
\end{align*}
\end{document}